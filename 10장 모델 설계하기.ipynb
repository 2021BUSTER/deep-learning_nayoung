{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compressed-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝을 구동하는 데 필요한 케라스 함수 호출\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classical-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 불러옴\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "talented-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실행할 때 마다 같은 결과를 출력하기 위한 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distant-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#준비된 수술 환자 데이터 불러옴\n",
    "Data_set = np.loadtxt(\"../dataset/ThoraricSurgery.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "internal-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:,0:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "median-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 구조를 짜고 층을 설정하는 부분\n",
    "model = Sequential() # 퍼셉트론 위에 숨겨진 퍼셉트론 층이 추가된 형태를 구현하기 위한 함수\n",
    "\n",
    "# 맨 마지막 층은 출력층이 되고 나머지는 은닉층의 역할을 함.\n",
    "#keras에서는 첫 번째 Dense가 은닉층 + 입력층의 역할을 함.<- input_dim 이용\n",
    "# model.add()를 이용해 층 추가, Dense 함수를 이용해 층의 구조 결정\n",
    "model.add(Dense(30,input_dim=17,activation='relu')) #은닉층. 30개의 노드, 입력데이터에서 값을 17개 가져옴, relu를 활성화 함수로 사용 \n",
    "model.add(Dense(1, activation='sigmoid')) #출력층. 출력값을 하나로 정해 보여줘야하기 때문에 노드는 1개, sigmoid를 활성화 함수로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "motivated-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 1s 2ms/sample - loss: 0.1495 - accuracy: 0.8404\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 280us/sample - loss: 0.1447 - accuracy: 0.8511\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 288us/sample - loss: 0.1448 - accuracy: 0.8511\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 289us/sample - loss: 0.1453 - accuracy: 0.8489\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 275us/sample - loss: 0.1438 - accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 273us/sample - loss: 0.1418 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 293us/sample - loss: 0.1425 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 261us/sample - loss: 0.1427 - accuracy: 0.8468\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 270us/sample - loss: 0.1446 - accuracy: 0.8489\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 322us/sample - loss: 0.1427 - accuracy: 0.8511\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 321us/sample - loss: 0.1429 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 269us/sample - loss: 0.1419 - accuracy: 0.8511\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 259us/sample - loss: 0.1424 - accuracy: 0.8489\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 263us/sample - loss: 0.1431 - accuracy: 0.8489\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 276us/sample - loss: 0.1422 - accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 247us/sample - loss: 0.1405 - accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 252us/sample - loss: 0.1390 - accuracy: 0.8489\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 276us/sample - loss: 0.1398 - accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 292us/sample - loss: 0.1446 - accuracy: 0.8489\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 297us/sample - loss: 0.1426 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 261us/sample - loss: 0.1410 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 286us/sample - loss: 0.1396 - accuracy: 0.8532\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 257us/sample - loss: 0.1334 - accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 252us/sample - loss: 0.1362 - accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 255us/sample - loss: 0.1422 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 274us/sample - loss: 0.1407 - accuracy: 0.8489\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 257us/sample - loss: 0.1387 - accuracy: 0.8532\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 260us/sample - loss: 0.1387 - accuracy: 0.8489\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 262us/sample - loss: 0.1339 - accuracy: 0.8511\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 260us/sample - loss: 0.1376 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 271us/sample - loss: 0.1349 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 261us/sample - loss: 0.1296 - accuracy: 0.8532\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 277us/sample - loss: 0.1283 - accuracy: 0.8511\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 263us/sample - loss: 0.1321 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 259us/sample - loss: 0.1411 - accuracy: 0.8532\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 282us/sample - loss: 0.1388 - accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 306us/sample - loss: 0.1369 - accuracy: 0.8489\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 298us/sample - loss: 0.1372 - accuracy: 0.8468\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 288us/sample - loss: 0.1333 - accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 277us/sample - loss: 0.1290 - accuracy: 0.8511\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 252us/sample - loss: 0.1276 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 265us/sample - loss: 0.1383 - accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 282us/sample - loss: 0.1367 - accuracy: 0.8532\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 255us/sample - loss: 0.1317 - accuracy: 0.8532\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 248us/sample - loss: 0.1327 - accuracy: 0.8553\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 267us/sample - loss: 0.1259 - accuracy: 0.8511\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 267us/sample - loss: 0.1258 - accuracy: 0.8553\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 263us/sample - loss: 0.1359 - accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 263us/sample - loss: 0.1329 - accuracy: 0.8426\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 276us/sample - loss: 0.1362 - accuracy: 0.8489\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 241us/sample - loss: 0.1400 - accuracy: 0.8511\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1407 - accuracy: 0.8511\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 272us/sample - loss: 0.1373 - accuracy: 0.8511\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 280us/sample - loss: 0.1314 - accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 245us/sample - loss: 0.1305 - accuracy: 0.8532\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 248us/sample - loss: 0.1303 - accuracy: 0.8574\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 238us/sample - loss: 0.1338 - accuracy: 0.8511\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 239us/sample - loss: 0.1364 - accuracy: 0.8532\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 260us/sample - loss: 0.1280 - accuracy: 0.8489\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 278us/sample - loss: 0.1321 - accuracy: 0.8532\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 239us/sample - loss: 0.1405 - accuracy: 0.8511\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 266us/sample - loss: 0.1226 - accuracy: 0.8553\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 262us/sample - loss: 0.1402 - accuracy: 0.8447\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 264us/sample - loss: 0.1388 - accuracy: 0.8532\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 259us/sample - loss: 0.1366 - accuracy: 0.8574\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 277us/sample - loss: 0.1344 - accuracy: 0.8596\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 274us/sample - loss: 0.1246 - accuracy: 0.8617\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 266us/sample - loss: 0.1264 - accuracy: 0.8574\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 243us/sample - loss: 0.1292 - accuracy: 0.8532\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 259us/sample - loss: 0.1306 - accuracy: 0.8511\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 289us/sample - loss: 0.1290 - accuracy: 0.8574\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 235us/sample - loss: 0.1282 - accuracy: 0.8426\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 254us/sample - loss: 0.1245 - accuracy: 0.8596\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 253us/sample - loss: 0.1231 - accuracy: 0.8532\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 254us/sample - loss: 0.1228 - accuracy: 0.8574\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 254us/sample - loss: 0.1218 - accuracy: 0.8532\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 273us/sample - loss: 0.1249 - accuracy: 0.8574\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 262us/sample - loss: 0.1341 - accuracy: 0.8489\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 240us/sample - loss: 0.1318 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 246us/sample - loss: 0.1316 - accuracy: 0.8468\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 267us/sample - loss: 0.1210 - accuracy: 0.8574\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 277us/sample - loss: 0.1229 - accuracy: 0.8553\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 275us/sample - loss: 0.1234 - accuracy: 0.8553\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 268us/sample - loss: 0.1236 - accuracy: 0.8468\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 272us/sample - loss: 0.1277 - accuracy: 0.8489\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 268us/sample - loss: 0.1254 - accuracy: 0.8553\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 292us/sample - loss: 0.1310 - accuracy: 0.8553\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 261us/sample - loss: 0.1220 - accuracy: 0.8511\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 223us/sample - loss: 0.1202 - accuracy: 0.8532\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 275us/sample - loss: 0.1233 - accuracy: 0.8553\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 280us/sample - loss: 0.1194 - accuracy: 0.8553\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 286us/sample - loss: 0.1175 - accuracy: 0.8574\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 271us/sample - loss: 0.1376 - accuracy: 0.8447\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 273us/sample - loss: 0.1321 - accuracy: 0.8596\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 253us/sample - loss: 0.1300 - accuracy: 0.8638\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 245us/sample - loss: 0.1215 - accuracy: 0.8511\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 240us/sample - loss: 0.1213 - accuracy: 0.8596\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 224us/sample - loss: 0.1303 - accuracy: 0.8447\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 240us/sample - loss: 0.1199 - accuracy: 0.8638\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 251us/sample - loss: 0.1192 - accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e5e79b66c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 정해진 모델을 컴퓨터가 알아들을 수 있게 컴파일하는 부분\n",
    "# 오차함수로 평균제곱오차함수(mean_squared_error) 사용, 최적화 방법으로 adam사용\n",
    "# metrics() 함수는 모델이 컴파일 될 때 모델 수행 결과를 나타내도록 설정하는 부분\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=100,batch_size=10) # 모델 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
